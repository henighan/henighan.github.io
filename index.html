<!-- Heading -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <link rel="stylesheet" type="text/css" href="style.css">

  <title>Tom Henighan</title>

  <!-- Google Analytics -->
  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date(); a = s.createElement(o),
        m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-103300506-1', 'auto');
    ga('send', 'pageview');

  </script>
</head>

<!-- Body -->

<body>

  <div class="container">

    <!-- Start Header -->
    <div class="header-row">
      <div class="header-text">
        <p align="center">
          <name>Tom Henighan</name>
        </p>
        I'm a member of the technical staff at <a target="_blank" href="https://anthropic.com">Anthropic</a>.
        My
        previous roles include member of the technical staff at
        <a target="_blank" href="https://openai.com"> OpenAI</a>
        and artificial intelligence engineer at <a target="_blank" href="https://beehive.ai/"> Beehive
          AI</a>. I did my PhD in Physics at Stanford.
        <p>
        </p>
        <p>
          Some selected publications and projects can be found below.
        </p>
        <p align="center">
          <a target="_blank" href="https://github.com/henighan">Github</a>
          &nbsp;/&nbsp;
          <a target="_blank" href="https://scholar.google.com/citations?user=8h3AFugAAAAJ&hl=en">
            Scholar</a>
          &nbsp;/&nbsp;
          <a target="_blank" href="https://www.linkedin.com/in/tom-henighan-757498123/">LinkedIn</a>
        </p>
      </div>
      <div class="header-pic">
        <img src="./images/maface6_round.png">
      </div>
    </div>
    <!-- End Header -->

    <!-- Start Anthropic -->
    <heading>Anthropic</heading>
    <p>
      As one of Anthropic's first employees, I helped build out and manage some
      of our core infrastructure to support training and evaluation of large
      language models. I'm now focusing on interpretability full time.
    </p>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://transformer-circuits.pub/2023/toy-double-descent/index.html">
          <img src="./images/toy_frac_dims_downsized.jpg">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://transformer-circuits.pub/2023/toy-double-descent/index.html">
            <papertitle>
              Superposition, Memorization, and Double Descent
            </papertitle>
          </a>
          <br>
          <strong>Tom Henighan*</strong>, Shan Carter*, Tristan Hume*, Nelson Elhage*, Robert Lasenby, Stanislav Fort,
          Nicholas Schiefer, Christopher Olah
          <br>
          <em>
            transformer-circuits
          </em>, 2023 &nbsp;
          <br>
          <a target="_blank" href="https://transformer-circuits.pub/2023/toy-double-descent/index.html">Paper</a>
        </p>
        <p>
          We extend our previous toy-model work to the finite data regime, revealing how and when they memorize training
          examples.
        </p>
      </div>
    </div>


    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://transformer-circuits.pub/2022/toy_model/index.html">
          <img src="./images/toy_model.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://transformer-circuits.pub/2022/toy_model/index.html">
            <papertitle>
              Toy Models of Superposition
            </papertitle>
          </a>
          <br>
          N Elhage*, T Hume*, C Olsson*, N Schiefer*,
          <strong>T Henighan</strong>,
          S Kravec, ZH Dodds, R Lasenby, D Drain, C Chen, R Grosse, S
          McCandlish, J Kaplan, D Amodei, M Wattenberg*, C Olah
          <br>
          <em>
            transformer-circuits
          </em>, 2022 &nbsp;
          <br>
          <a target="_blank" href="https://transformer-circuits.pub/2022/toy_model/index.html">Paper</a>
        </p>
        <p>
          Neural networks often pack many unrelated concepts into a single
          neuron - a puzzling phenomenon known as 'polysemanticity' which makes
          interpretability much more challenging. In this work, we build
          toy models where the origins of polysemanticity can be fully
          understood.
        </p>
      </div>
    </div>


    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://arxiv.org/pdf/2207.05221.pdf">
          <img src="./images/pik_idk.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://arxiv.org/pdf/2207.05221.pdf">
            <papertitle>
              Language Models (Mostly) Know What They Know
            </papertitle>
          </a>
          <br>
          S Kadavath*, T Conerly, A Askell,
          <strong>T Henighan</strong>,
          D Drain, E Perez, N Schiefer, ZH Dodds, N DasSarma, E Tran-Johnson, S
          Johnston, S El-Showk, A Jones, N Elhage, T Hume, A Chen, Y Bai, S
          Bowman, S Fort, D Ganguli, D Hernandez, J Jacobson, J Kernion, S
          Kravec, L Lovitt, K Ndousse, C Olsson, S Ringer, D Amodei, T Brown, J
          Clark, N Joseph, B Mann, S McCandlish, C Olah, J Kaplan*
          <br>
          <em>
            Arxiv
          </em>, 2022 &nbsp;
          <br>
          <a target="_blank" href="https://arxiv.org/pdf/2207.05221.pdf">Paper</a>
        </p>
        <p>
          We show that language models can evaluate whether what they say is
          true, and predict ahead of time whether they'll be able to answer
          questions correctly.
        </p>
      </div>
    </div>


    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://arxiv.org/abs/2204.05862">
          <img src="./images/align2.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://arxiv.org/abs/2204.05862">
            <papertitle>
              Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback
            </papertitle>
          </a>
          <br>
          Y Bai*, A Jones*, K Ndousse*,
          A Askell, A Chen, N DasSarma, D Drain, S Fort,
          D Ganguli,
          <strong>T Henighan</strong>,
          N Joseph, S Kadavath, J Kernion,
          T Conerly, S El-Showk, N Elhage, Z Hatfield-Dodds,
          D Hernandez, T Hume, S Johnston, S Kravec, L Lovitt,
          N Nanda, C Olsson, D Amodei, T Brown, J Clark,
          S McCandlish, C Olah, B Mann, J Kaplan
          <br>
          <em>
            Arxiv
          </em>, 2022 &nbsp;
          <br>
          <a target="_blank" href="https://arxiv.org/abs/2204.05862">Paper</a>
        </p>
        <p>
          Anthropic's second AI Alignment paper. We've trained a natural
          language assistant to be more helpful and harmless by using
          reinforcement learning with human feedback (RLHF).
        </p>
      </div>
    </div>


    <div class="content-row">
      <div class="content-pic">
        <a target="_blank"
          href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html">
          <img src="./images/interp2.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank"
            href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html">
            <papertitle>
              In-context Learning and Induction Heads
            </papertitle>
          </a>
          <br>
          C Olsson*, N Elhage*, N Nanda*, N
          Joseph&dagger;, N DasSarma&dagger;,
          <strong>T Henighan&dagger;</strong>,
          B Mann&dagger;, A Askell, Y Bai, A Chen, T Conerly, D
          Drain, D Ganguli, Z Hatfield-Dodds, D Hernandez, S
          Johnston, A Jones, J Kernion, L Lovitt, K Ndousse,
          D Amodei, T Brown, J Clark, J Kaplan, S McCandlish,
          C Olah
          <br>
          <em>
            transformer-circuits
          </em>, 2022 &nbsp;
          <br>
          <a target="_blank"
            href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html">Paper</a>
        </p>
        <p>
          Anthropic's second interpretability paper explores the hypothesis that induction heads (discovered in our
          first interpretability paper) are the mechanism driving in-context learning.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://arxiv.org/abs/2202.07785">
          <img src="./images/soc1.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://arxiv.org/abs/2202.07785">
            <papertitle>
              Predictability and Surprise in Large Generative Models
            </papertitle>
          </a>
          <br>
          D Ganguli*, D Hernandez*, L Lovitt*, N DasSarma&dagger;,
          <strong>T Henighan&dagger;</strong>,
          A Jones&dagger;, N Joseph&dagger;, J Kernion&dagger;, B Mann&dagger;, A Askell, Y Bai,
          A Chen, T Conerly, D Drain, N Elhage, S El Showk, S Fort,
          Z Hatfield-Dodds, S Johnston, S Kravec, N Nanda, K Ndousse,
          C Olsson, D Amodei, D Amodei, T Brown, J Kaplan,
          Sam McCandlish, Chris Olah, Jack Clark
          <br>
          <em>
            Arxiv
          </em>, 2022 &nbsp;
          <br>
          <a target="_blank" href="https://arxiv.org/abs/2202.07785">Paper</a>
        </p>
        <p>
          Anthropic's first societal impacts paper explores the technical traits of
          large generative models and the motivations and challenges people face
          in building and deploying them.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://transformer-circuits.pub/2021/framework/index.html">
          <img src="./images/interp1.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://transformer-circuits.pub/2021/framework/index.html">
            <papertitle>
              A Mathematical Framework for Transformer Circuits
            </papertitle>
          </a>
          <br>
          N Elhage*&dagger;, N Nanda*, C Olsson*,
          <strong>T Henighan&dagger;</strong>
          N Joseph&dagger;, B Mann&dagger;,
          A Askell, Y Bai, A Chen, T Conerly, N DasSarma, D Drain,
          D Ganguli, Z Hatfield-Dodds, D Hernandez, A Jones, J Kernion,
          L Lovitt, K Ndousse, D Amodei, T Brown, J Clark, J Kaplan,
          S McCandlish, C Olah
          <br>
          <em>
            transformer-circuits
          </em>, 2021 &nbsp;
          <br>
          <a target="_blank" href="https://transformer-circuits.pub/2021/framework/index.html">Paper</a>
        </p>
        <p>
          Anthropic's first interpretability paper.
          We try to mechanistically understand some small, simplified
          transformers in detail, as a first step toward understanding large
          transformer language models.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://arxiv.org/abs/2112.00861">
          <img src="./images/prompt_vs_distillation_accuracy.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://arxiv.org/abs/2112.00861">
            <papertitle>
              A General Language Assistant as a Laboratory for Alignment
            </papertitle>
          </a>
          <br>
          A Askell*, Y Bai*, A Chen*, D Drain*, D Ganguli*,
          <strong>T Henighan&dagger;</strong>
          A Jones&dagger;, N Joseph&dagger;, B Mann*, N DasSarma, N Elhage,
          Z Hatfield-Dodds, D Hernandez, J Kernion, K Ndousse,
          C Olsson, D Amodei, T Brown, J Clark, S McCandlish, Chris Olah,
          Jared Kaplan
          <br>
          <em>
            Arxiv
          </em>, 2021 &nbsp;
          <br>
          <a target="_blank" href="https://arxiv.org/abs/2112.00861">Paper</a>
        </p>
        <p>
          Anthropic's first AI alignment paper, focused on simple baselines and
          investigations. We compare scaling trends for alignment from
          prompting, imitation learning, and preference modeling, and find ways
          to simplify these techniques and improve their sample efficiency.
        </p>
      </div>
    </div>
    <!-- End Anthropic -->

    <!-- Start Open AI -->
    <heading>OpenAI</heading>
    <p>
      My research at OpenAI focused on scaling laws. I also contributed to the GPT-3 project.
    </p>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://arxiv.org/abs/2102.01293">
          <img src="./images/transfer_scaling.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://arxiv.org/abs/2102.01293">
            <papertitle>
              Scaling Laws for Transfer
            </papertitle>
          </a>
          <br>
          D Hernandez, J Kaplan, <strong>T Henighan</strong>, S McCandlish
          <br>
          <em>
            Arxiv
          </em>, 2021 &nbsp;
          <br>
          <a target="_blank" href="https://arxiv.org/abs/2102.01293">Paper</a>
        </p>
        <p>
          We studied the empirical scaling of pre-training on one
          dataset, then fine-tuning to another. We find the
          "effective data transferred" from pre-training to
          fine-tuning follows predictable trends.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://arxiv.org/abs/2010.14701">
          <img src="./images/params_vs_model_size.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://arxiv.org/abs/2010.14701">
            <papertitle>
              Scaling Laws for Autoregressive Generative Modeling
            </papertitle>
          </a>
          <br>
          <strong>T Henighan</strong>*, J Kaplan*, M Katz*, M Chen, C
          Hesse, J Jackson, H Jun, T Brown, P Dhariwal, S Gray, C
          Hallacy, B Mann, A Radford, A Ramesh, N Ryder, D Ziegler,
          J Schulman, D Amodei, S McCandlish
          <br>
          <em>
            Arxiv
          </em>, 2020 &nbsp;
          <br>
          <a target="_blank" href="https://arxiv.org/abs/2010.14701">Paper</a> /
          <a target="_blank" href="https://www.skynettoday.com/podcast/scaling-laws">Podcast Interview</a>
        </p>
        <p>
          We studied empirical scaling laws in four domains:
          image modeling, video modeling, multimodal image+text
          modeling, and mathematical problem solving. In all cases,
          autoregressive Transformers smoothly improve in performance
          as model size and compute budgets increase, following a
          power-law plus constant scaling law.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://arxiv.org/abs/2005.14165">
          <img src="./images/gpt3_scaling.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://arxiv.org/abs/2005.14165">
            <papertitle>
              Language Models are Few-Shot Learners
            </papertitle>
          </a>
          <br>
          T Brown*, B Mann*, N Ryder*, M Subbiah*, J Kaplan, P
          Dhariwal, A Neelakantan, P Shyam, G Satstry, A Askell, S
          Agarwal, A Herbert-Voss, G Krueger,
          <strong>T Henighan</strong>,
          R Child, A Ramesh, D Ziegler, J Wu, C
          Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess,
          J Clark, C Berner, S McCandlish, A Radford, I Sutskever, D
          Amodei
          <br>
          <em>
            Arxiv
          </em>, 2020 &nbsp;
          <br>
          <a target="_blank" href="https://arxiv.org/abs/2005.14165">Paper</a> /
          <a target="_blank" href="https://arxiv.org/abs/2005.14165">Wikipedia Article</a>
        </p>
        <p>
          This is the paper which describes GPT-3, a 175 billion
          parameter language model which was competitive with
          state-of-the-art performance on a wide variety of
          benchmarks.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://arxiv.org/abs/2001.08361">
          <img src="./images/lang_scaling.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://arxiv.org/abs/2001.08361">
            <papertitle>
              Scaling Laws for Neural Language Models
            </papertitle>
          </a>
          <br>
          J Kaplan*, S McCandlish*,
          <strong>T Henighan</strong>,
          T Brown, B Chess, R Child, S Gray, A Radford, J Wu, D Amodei
          <br>
          <em>
            Arxiv
          </em>, 2020 &nbsp;
          <br>
          <a target="_blank" href="https://arxiv.org/abs/2001.08361">Paper</a>
        </p>
        <p>
          We found that language modeling loss scales as a power-law
          with model size, dataset size, and the amount of compute
          used for training, with some trends spanning more than
          seven orders of magnitude.
        </p>
      </div>
    </div>
    <!-- End Open AI -->

    <!-- Start Projects -->
    <heading>Projects</heading>
    <p>
      Some of these were projects for classes I took while at
      Stanford, while others were just for fun.
    </p>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://github.com/henighan/deeprl-intro">
          <img src="./images/ppo_halfcheetah_compressed.gif">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://github.com/henighan/deeprl-intro">
            <papertitle>
              Deep Reinforcement Learning with OpenAI Gym
            </papertitle>
          </a>
          <br>
          <strong>Tom Henighan</strong>
          <br>
          <em>
            Weekend Project
          </em>, 2019 &nbsp;
          <br>
          <a target="_blank" href="https://github.com/henighan/deeprl-intro">Github</a>
        </p>
        <p>
          Read through
          <a target="_blank" href="https://spinningup.openai.com/en/latest/">
            OpenAI's spinning up</a> materials and was
          inspired to implement some algorithms myself. This gif
          is the 'HalfCheetah-v2' environment. I trained a
          proximal policy optimization agent to make it run.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://github.com/henighan/blackjack-rl">
          <img src="./images/strategy_card.gif">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://github.com/henighan/blackjack-rl">
            <papertitle>
              Blackjack Reinforcement Learning
            </papertitle>
          </a>
          <br>
          <strong>Tom Henighan</strong>
          <br>
          <em>
            Weekend Project
          </em>, 2019 &nbsp;
          <br>
          <a target="_blank" href="https://github.com/henighan/blackjack-rl">Github</a>
        </p>
        <p>
          Built from scratch a little python package for using
          reinforcement learning to find the optimal strategy
          on blackjack. The gif to the left shows how the randomly-
          initialized optimal strategy evolves as the agent trains
          over more episodes.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="mnist_app/index.html">
          <img src="./images/mnist_app.gif">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="./mnist_app/index.html">
            <papertitle>
              MNIST Tensorflow.js webapp
            </papertitle>
          </a>
          <br>
          <strong>Tom Henighan</strong>
          <br>
          <em>
            Weekend Project
          </em>, 2018 &nbsp;
          <br>
          <a target="_blank" href="mnist_app/index.html">App</a>
        </p>
        <p>
          Trained a convolution neural network for the task of
          recoginizing digits from the
          <a target="_blank" href="http://yann.lecun.com/exdb/mnist/">
            MNIST dataset</a>. Deployed this network using
          <a target="_blank" href="https://js.tensorflow.org/">
            tensorflow.js</a>, so the network actually runs
          in your browser! (And saves the server costs of hosting
          it :)). Built a little webapp so you can write a digit
          in the box and get the network's prediction. Tuned
          the network's hyperparameters using the implementation of
          bayesian optimization from
          <a target="_blank" href="https://scikit-optimize.github.io/">
            skopt</a>.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="pdfs/stylexfer_examples.pdf">
          <img src="./images/stylexfer_maface.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="./pdfs/cs231n-project.pdf">
            <papertitle>
              Spatial Control of Style Blending in Neural Style Transfer
            </papertitle>
          </a>
          <br>
          <strong>Tom Henighan</strong>
          <br>
          <em>
            CS231n: Convolutional Neural Networks for Visual Recognition
          </em>, 2017 &nbsp;
          <br>
          <a target="_blank" href="./pdfs/cs231n-project.pdf">PDF</a>
          /
          <a target="_blank" href="./pdfs/stylexer_poster.pdf">Poster</a>
          /
          <a target="_blank" href="pdfs/stylexfer_examples.pdf">
            Examples
          </a>
        </p>
        <p>
          Implemented an algorithm for neural style transfer
          which takes in one or more "style" images (usually
          paintings) and a "content" image (usually a photograph)
          and renders the content image in the "style" of the
          style image. Inspired by the work of
          <a target="_blank"
            href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Gatys_Image_Style_Transfer_CVPR_2016_paper.html">
            Gatys et al</a>, my implementation allows for spatial control
          of blending multiple styles, allowing for smooth
          transitions from one style to another. See some examples
          <a target="_blank" href="pdfs/stylexfer_examples.pdf">
            here</a>.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="pdfs/final_poster.pdf">
          <img src="./images/context_vec_diff.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="./pdfs/iterative-attention-network.pdf">
            <papertitle>
              Iterative Attention Networks for Question Answering
            </papertitle>
          </a>
          <br>
          <strong>Tom Henighan</strong>
          <br>
          <em>
            CS224n: Natural Language Processing with Deep Learning
          </em>, 2017 &nbsp;
          <br>
          <a target="_blank" href="./pdfs/iterative-attention-network.pdf">PDF</a>
          /
          <a target="_blank" href="./pdfs/final_poster.pdf">Poster</a>
          /
          <a target="_blank" href="pdfs/squad_itatt_examples.pdf">
            Example Predictions
          </a>
        </p>
        <p>
          Designed a deep learning model which takes
          in a paragraph from wikipedia and then answers a
          question based on that paragraph. Trained on the
          <a target="_blank" href="https://rajpurkar.github.io/SQuAD-explorer/">
            SQuAD
          </a> dataset. My
          <a target="_blank" href="http://web.stanford.edu/class/cs224n/reports.html">
            poster was recognized
          </a> as outstanding by the course staff. Check out
          some example answers produced by the model
          <a target="_blank" href="./pdfs/squad_itatt_examples.pdf">
            here
          </a>.
        </p>
      </div>
    </div>
    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="./money_app/index.html">
          <img src="./images/money_map.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="./money_app/index.html">
            <papertitle>
              Predicting Bill Votes in the House of Representatives
            </papertitle>
          </a>
          <br>
          <strong>Tom Henighan</strong>,
          Scott Kravitz
          <br>
          <em>CS229: Machine Learning</em>, 2015
          <br>
          <a target="_blank" href="./money_app/index.html">
            Interactive Visualization</a>
          /
          <a target="_blank" href="./pdfs/vote_prediction.pdf">PDF</a>
          /
          <a target="_blank" href="pdfs/poster_final.pdf">
            Poster</a>
        </p>
        <p>
          We created a model for predicting how a member of
          congress would vote not based on their voting history,
          but on their party and their campaign contributions.
          Check out the
          <a target="_blank" href="./money_app/index.html">
            interactive visualization
          </a> which shows funding by district and economic
          sector.
        </p>
      </div>
    </div>
    <!-- End Projects -->

    <!-- Start PhD -->
    <heading>PhD Research</heading>
    <p>
      I completed my PhD in the Physics department at Stanford.
      Under my advisor, David Reis, I studied atomic motion in solids
      using the
      <a target="_blank" href="https://youtu.be/t7jUZwhZdd0">
        Linac Coherent Light Source</a>.
    </p>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.121.125901">
          <img src="./images/a1g_decay.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.121.125901">
            <papertitle>
              Direct Measurement of Anharmonic Decay Channels of a Coherent Phonon
            </papertitle>
          </a>
          <br>
          S W Teitelbaum, <strong>T Henighan</strong>, Y Huang, H Liu, M P
          Jiang, D Zhu, M Chollet, T Sato, E D Murray, S Fahy, S O&#39;Mahony, T P
          Bailey, C Uher, M Trigo, and D A Reis
          <br>
          <em>
            Physical Review Letters
          </em>, 2018 &nbsp;
          <br>
          <a target="_blank" href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.121.125901">
            Phys Rev Lett</a>
        </p>
        <p>
          We made time and wavevector resolved measurements of phonon decay with
          X-ray diffraction. More specifically, we measured an optically excited
          coherent zone-center phonon parametrically drive mean-square
          displacements in lower frequency phonons across the brillouin zone.
        </p>
      </div>
    </div>


    <div class="content-row">
      <div class="content-pic">
        <iframe src="https://www.youtube.com/embed/HXx_QI5htRY?ecver=2">
        </iframe>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://youtu.be/HXx_QI5htRY">
            <papertitle>
              Dissertation: Couplings of Phonons to Light
              and One Another Studied with LCLS
            </papertitle>
          </a>
          <br>
          <strong>Tom Henighan</strong>, advisor: David Reis
          <br>
          <em>
            Stanford University Department of Physics
          </em>, 2016 &nbsp;
          <br>
          <a target="_blank" href="https://youtu.be/HXx_QI5htRY">
            Defense</a>
          /
          <a target="_blank" href="https://searchworks.stanford.edu/view/12082113">
            Thesis</a>
        </p>
        <p>
          The
          <a target="_blank" href="https://youtu.be/t7jUZwhZdd0">
            Linac Coherent Light Source
          </a>(LCLS) is the first x-ray source of its kind,
          providing a combination of atomic-scale wavelengths,
          temporally-short pulses, and high-flux. This allows for
          previously impossible time-domain measurements of
          phonons. My collaborators and I demonstrated techinques
          that not only allow for measurement of phonon
          dispersions and lifetimes, but momentum-resolved
          phonon-phonon coupling.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://journals.aps.org/prb/abstract/10.1103/PhysRevB.94.020302">
          <img src="./images/two_pump.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://journals.aps.org/prb/abstract/10.1103/PhysRevB.94.020302">
            <papertitle>
              Control of two-phonon correlations and the mechanism
              of high-wavevector phonon generation by ultrafast
              light pulses
            </papertitle>
          </a>
          <br>
          <strong>T Henighan</strong>, M Trigo , M Chollet, J N Clark, S Fahy, J M Glownia,
          M P Jiang, M Kozina, H Liu, S Song, D Zhu, and D A Reis
          <br>
          <em>
            Physical Review B Rapid Communications
          </em>, 2016 &nbsp;
          <br>
          <a target="_blank" href="https://journals.aps.org/prb/abstract/10.1103/PhysRevB.94.020302">
            Phys Rev B</a>
          /
          <a target="_blank" href="https://arxiv.org/abs/1510.02403">
            arXiv
          </a>
        </p>
        <p>
          We showed that in Fourier-Transfor Inelastic X-ray
          Scattering (FTIXS) measurements on high-quality crystals,
          the pump laser couples to high-wavevector phonons
          primarily through second-order processes.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="https://journals.aps.org/prb/abstract/10.1103/PhysRevB.93.220301">
          <img src="./images/iron_wiggles.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="https://journals.aps.org/prb/abstract/10.1103/PhysRevB.93.220301">
            <papertitle>
              Generation mechanism of terahertz coherent acoustic
              phonons in Fe
            </papertitle>
          </a>
          <br>
          <strong>T Henighan</strong>, M Trigo, Stefano Bonetti, P Granitzka, D Higley, Z Chen, M P Jiang,
          R Kukreja, A Gray, A H Reid, E Jal, M C Hoffmann,
          M Kozina, S Song, M Chollet, D Zhu, P F Xu, J Jeong,
          K Carva, P Maldonado, P M Oppeneer, M G Samant,
          S P Parkin, D A Reis, and H A Durr
          <br>
          <em>
            Physical Review B Rapid Communications
          </em>, 2016 &nbsp;
          <br>
          <a target="_blank" href="https://journals.aps.org/prb/abstract/10.1103/PhysRevB.93.220301">
            Phys Rev B</a>
          /
          <a target="_blank" href="https://arxiv.org/pdf/1509.03348.pdf">
            arXiv
          </a>
        </p>
        <p>
          We were able to make time-resolved measurements
          of acoustic phonons with frequencies up to 3.5 THz
          in iron using
          <a target="_blank" href="https://youtu.be/t7jUZwhZdd0">
            LCLS</a>.
        </p>
      </div>
    </div>
    <!-- End PhD -->

    <!-- Start Fulbright -->
    <heading>Fulbright Research</heading>
    <p>
      I spent a year at
      <a target="_blank" href="http://www.tudelft.nl/en/">
        Delft Institute of Technology
      </a>(TUDelft) as a
      <a target="_blank" href="https://en.wikipedia.org/wiki/Fulbright_Program">
        Fulbright Scholar
      </a>doing biophysics research in the lab of Cees Dekker.
    </p>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0041432">
          <img src="./images/cycloid.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0041432">
            <papertitle>
              Magnetic Forces and DNA Mechanics in
              Multiplexed Magnetic Tweezers
            </papertitle>
          </a>
          <br>
          I De Vlaminck*,
          <strong>T Henighan</strong>*, M T J van Loenhout,
          D Burnham, C Dekker *authors contributed equally
          <br>
          <em>
            PLOS ONE
          </em>, 2012 &nbsp;
          <br>
          <a target="_blank" href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0041432">
            PLOS ONE</a>
        </p>
        <p>
          We demonstrated ways of parallelizing single-molecule
          measurements with magnetic tweezers, allowing for
          simultaneous measurement of hundreds of molecules
          instead of just a few.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="http://pubs.acs.org/doi/abs/10.1021/nl203299e">
          <img src="./images/parallel_tweezers.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="http://pubs.acs.org/doi/abs/10.1021/nl203299e">
            <papertitle>
              Highly Parallel Magnetic Tweezers by
              Targeted DNA Tethering
            </papertitle>
          </a>
          <br>
          I De Vlaminck,
          <strong>T Henighan</strong>, M T J van Loenhout,
          I Pfeiffer, J Huijts, J W J Kerssemakers, A J Katan,
          A van Langen-Suurling, E van der Drift, C Wyman, C Dekker
          <br>
          <em>
            Nano Letters
          </em>, 2011 &nbsp;
          <br>
          <a target="_blank" href="http://pubs.acs.org/doi/abs/10.1021/nl203299e">
            Nano Lett</a>
        </p>
        <p>
          Patterning tether sites of the DNA strands allowed
          for furter improvement in parallelization capacity.
        </p>
      </div>
    </div>
    <!-- End Fulbright -->

    <!-- Start Undergrad -->
    <heading>Undergraduate Research</heading>
    <p>
      I did my bachelors at
      <a target="_blank" href="https://youtu.be/Mc6pr8Iui4k">
        The Ohio State University
      </a>
      where I was advised by Prof Sooryakumar.
      I majored in engineering physics with a focus
      in electrical engineering.
    </p>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="http://aip.scitation.org/doi/10.1063/1.3562037">
          <img src="./images/magnetic_potential.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="http://aip.scitation.org/doi/10.1063/1.3562037">
            <papertitle>
              Undergraduate Thesis: Patterned magnetic traps for
              magnetophoretic
              assembly and actuation of microrotor pumps
            </papertitle>
          </a>
          <br>
          <strong>T Henighan</strong>, D Giglio, A Chen,
          G Vieira, and R Sooryakumar
          <br>
          <em>
            Applied Physics Letters
          </em>, 2011 &nbsp;
          <br>
          <a target="_blank" href="http://aip.scitation.org/doi/10.1063/1.3562037">
            App Phys Lett
          </a>
          /
          <a target="_blank" href="https://kb.osu.edu/dspace/handle/1811/45427">
            Undergraduate Thesis
          </a>

        </p>
        <p>
          We demonstrated a magnetically controlled microfluidic
          pump. The pump consisted of a magnetic microsphere
          trapped by the magnetic field gradient produced
          by a patterned paramagnetic film on the floor
          of the microchannel. Time-varying magnetic fields
          positioned and spun the microsphere, activating
          the pump.
        </p>
      </div>
    </div>

    <div class="content-row">
      <div class="content-pic">
        <a target="_blank" href="http://dx.doi.org/10.1016/j.bpj.2009.10.036">
          <img src="./images/moving_microbeads.png">
        </a>
      </div>
      <div class="content-text">
        <p>
          <a target="_blank" href="http://dx.doi.org/10.1016/j.bpj.2009.10.036">
            <papertitle>
              Manipulation of Magnetically Labeled and Unlabeled
              Cells with Mobile Magnetic Traps
            </papertitle>
          </a>
          <br>
          <strong>T Henighan</strong>, A Chen, G Vieira,
          A J Hauser, F Y Yang, J J Chalmers, and R Sooryakumar
          <br>
          <em>
            Biophysical Journal
          </em>, 2011 &nbsp;
          <br>
          <a target="_blank" href="http://www.sciencedirect.com/science/article/pii/S0006349509016786">
            Biophys
          </a>
          /
          <a target="_blank" href="https://youtu.be/oy4fyFDLUsY">
            Dancing Microspheres
          </a>
          /
          <a targed="blank" href="https://www.google.com/patents/US8906691">
            Patent
          </a>
        </p>
        <p>
          Using patterned paramagnetic disks of micron scale
          diameter and 10s of nm thickness and externally
          applied weak (~10's of Oe) magnetic fields, we could
          control the position of magnetic microspheres on a
          lab-on-chip device.
        </p>
      </div>
    </div>
    <!-- End Undergrad -->

  </div> <!-- End Container div -->

  <footer>
    <p align="right">
      <font size="2">
        <a target="_blank" href="https://people.eecs.berkeley.edu/~barron/">
          thanks jon!
        </a>
      </font>
  </footer>

</html>